{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting English Hand-Drawn Chars74k Data to JSON\n",
    "\n",
    "By [Allison Parrish](http://www.decontextualize.com/)\n",
    "\n",
    "This is just a quick notebook to convert the stroke trajectories of the hand-drawn English letters in the [Chars74k](http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/) dataset to JSON. (See bibliography for paper reference.) I wanted to use this data for art reasons, but the dataset only comes supplied as MATLAB `.m` files. After spending an hour or so trying to figure out how MATLAB works, I decided to just write some Python to just read in the files and parse the data. In the interest of making the data available more widely Follow along with this notebook to reproduce the process. I've supplied the JSON files in this repository.\n",
    "\n",
    "Here's [an example of the data in use](https://editor.p5js.org/allison.parrish/full/rJWnRELhQ).\n",
    "\n",
    "For this notebook to work, you'll need to [download a copy of the original data](http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/EnglishHnd.tgz). Don't decompress the file! Put it in the same directory as this notebook.\n",
    "\n",
    "First, the needed Python libs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the data comes as `.m` files, they don't contain arbitrary MATLAB code, and they're all formatted in exactly the same way (thank god). In the cell below, `parsedata` takes the content of one of these files and finds the stroke data, which is turned into lists of integers in `extractlists`. (I used integers because the stroke data didn't look like the original data actually had useful information in the fractional part of the number.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractlists(s):\n",
    "    lists = re.findall(\"\\[([^\\[\\]]*)\\];\", s, re.MULTILINE)\n",
    "    return [[int(float(y)) for y in x.split()] for x in lists]\n",
    "def parsedata(s):\n",
    "    row_match = re.search(r\"^rows = {([\\[\\];0-9.e+\\r\\n]+)};\", s)\n",
    "    col_match = re.search( r\"cols = {([\\[\\];0-9.e+\\r\\n]+)};\", s)\n",
    "    row_data = extractlists(row_match.group(1))\n",
    "    col_data = extractlists(col_match.group(1))\n",
    "    assert len(row_data) == len(col_data)\n",
    "    return [list(zip(col_data[i], row_data[i])) for i in range(len(row_data))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `charmap` string maps an index to the character at that index in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charmap = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "len(charmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the following bit of code does the magic, checking the filename of each file in the archive and extracting the information contained therein using the functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = defaultdict(lambda: [None]*55)\n",
    "with tarfile.open(\"./EnglishHnd.tgz\", \"r:gz\") as tgz:\n",
    "    for tarinfo in tgz:\n",
    "        if tarinfo.isfile() and tarinfo.name.endswith(\".m\"):\n",
    "            imgidx, dataidx = re.findall(\"img(\\d\\d\\d)_(\\d\\d\\d).m\", tarinfo.name)[0]\n",
    "            data = tgz.extractfile(tarinfo).read().decode('utf8')\n",
    "            chars[charmap[int(imgidx)-1]][int(dataidx)-1] = parsedata(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `chars` dictionary maps each letter in the dataset to a list of letterforms (55 for each letter), which in turn are lists of (x, y) coordinates (as tuples) for each point in the stroke:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(300, 439),\n",
       "  (330, 428),\n",
       "  (335, 421),\n",
       "  (338, 417),\n",
       "  (340, 413),\n",
       "  (342, 408),\n",
       "  (344, 404),\n",
       "  (346, 399),\n",
       "  (349, 393),\n",
       "  (351, 388),\n",
       "  (353, 383),\n",
       "  (356, 377),\n",
       "  (359, 370),\n",
       "  (364, 357),\n",
       "  (367, 351),\n",
       "  (370, 344),\n",
       "  (373, 337),\n",
       "  (375, 330),\n",
       "  (378, 323),\n",
       "  (382, 309),\n",
       "  (384, 302),\n",
       "  (389, 289),\n",
       "  (393, 275),\n",
       "  (395, 268),\n",
       "  (397, 262),\n",
       "  (400, 249),\n",
       "  (402, 243),\n",
       "  (404, 237),\n",
       "  (409, 220),\n",
       "  (411, 216),\n",
       "  (412, 211),\n",
       "  (414, 202),\n",
       "  (416, 195),\n",
       "  (418, 189),\n",
       "  (418, 187),\n",
       "  (419, 184),\n",
       "  (419, 182),\n",
       "  (420, 178),\n",
       "  (420, 177),\n",
       "  (420, 176),\n",
       "  (420, 175),\n",
       "  (420, 176),\n",
       "  (420, 177),\n",
       "  (420, 178),\n",
       "  (419, 179),\n",
       "  (419, 180),\n",
       "  (418, 184),\n",
       "  (417, 186),\n",
       "  (415, 194),\n",
       "  (414, 197),\n",
       "  (413, 201),\n",
       "  (413, 204),\n",
       "  (412, 208),\n",
       "  (412, 211),\n",
       "  (411, 215),\n",
       "  (410, 223),\n",
       "  (409, 227),\n",
       "  (408, 231),\n",
       "  (407, 235),\n",
       "  (404, 249),\n",
       "  (402, 258),\n",
       "  (400, 268),\n",
       "  (400, 278),\n",
       "  (398, 287),\n",
       "  (396, 298),\n",
       "  (394, 308),\n",
       "  (394, 314),\n",
       "  (391, 337),\n",
       "  (390, 343),\n",
       "  (389, 349),\n",
       "  (389, 360),\n",
       "  (389, 366),\n",
       "  (388, 372),\n",
       "  (389, 390),\n",
       "  (390, 396),\n",
       "  (391, 402),\n",
       "  (394, 418),\n",
       "  (396, 423),\n",
       "  (400, 432),\n",
       "  (404, 440),\n",
       "  (407, 444),\n",
       "  (410, 447),\n",
       "  (417, 452),\n",
       "  (421, 454),\n",
       "  (430, 457),\n",
       "  (434, 458),\n",
       "  (439, 458),\n",
       "  (447, 458),\n",
       "  (456, 455),\n",
       "  (460, 454),\n",
       "  (467, 450),\n",
       "  (470, 448),\n",
       "  (473, 446),\n",
       "  (478, 443),\n",
       "  (481, 439),\n",
       "  (482, 438),\n",
       "  (483, 433),\n",
       "  (483, 431),\n",
       "  (482, 429),\n",
       "  (482, 428),\n",
       "  (481, 427)],\n",
       " [(336, 264),\n",
       "  (374, 262),\n",
       "  (381, 261),\n",
       "  (396, 260),\n",
       "  (419, 258),\n",
       "  (426, 257),\n",
       "  (433, 256),\n",
       "  (440, 256),\n",
       "  (447, 255),\n",
       "  (453, 255),\n",
       "  (458, 254),\n",
       "  (471, 253),\n",
       "  (474, 253),\n",
       "  (479, 252),\n",
       "  (481, 252),\n",
       "  (482, 252),\n",
       "  (482, 251),\n",
       "  (481, 251),\n",
       "  (480, 251)]]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars['t'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump to JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"char74k.json\", \"w\") as fh:\n",
    "    json.dump(chars, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized data\n",
    "\n",
    "For my purposes, a problem with this dataset is that all of the characters are drawn at different places on the canvas. To fix this, the following cell creates a copy of the original dictionary and then \"normalizes\" each character by centering the coordinates on the point halfway between the X and Y extents of the character, so that the midpoint of the bounding box is at (0, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "chars_normalized = dict(chars)\n",
    "for ch, forms in chars_normalized.items():\n",
    "    for form in forms:\n",
    "        minx = min([item[0] for item in itertools.chain(*form)])\n",
    "        maxx = max([item[0] for item in itertools.chain(*form)])\n",
    "        miny = min([item[1] for item in itertools.chain(*form)])\n",
    "        maxy = max([item[1] for item in itertools.chain(*form)])\n",
    "        centerx = (minx + maxx) / 2\n",
    "        centery = (miny + maxy) / 2\n",
    "        for stroke in form:\n",
    "            for i, point in enumerate(stroke):\n",
    "                stroke[i] = (point[0] - centerx, point[1] - centery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(59.0, -94.0),\n",
       "  (34.0, -100.0),\n",
       "  (32.0, -101.0),\n",
       "  (29.0, -101.0),\n",
       "  (27.0, -101.0),\n",
       "  (24.0, -101.0),\n",
       "  (22.0, -102.0),\n",
       "  (17.0, -102.0),\n",
       "  (15.0, -102.0),\n",
       "  (12.0, -101.0),\n",
       "  (8.0, -101.0),\n",
       "  (5.0, -101.0),\n",
       "  (1.0, -101.0),\n",
       "  (-4.0, -101.0),\n",
       "  (-8.0, -100.0),\n",
       "  (-11.0, -100.0),\n",
       "  (-13.0, -99.0),\n",
       "  (-17.0, -98.0),\n",
       "  (-19.0, -97.0),\n",
       "  (-23.0, -95.0),\n",
       "  (-24.0, -94.0),\n",
       "  (-26.0, -93.0),\n",
       "  (-30.0, -91.0),\n",
       "  (-32.0, -90.0),\n",
       "  (-33.0, -89.0),\n",
       "  (-35.0, -88.0),\n",
       "  (-37.0, -86.0),\n",
       "  (-39.0, -85.0),\n",
       "  (-40.0, -84.0),\n",
       "  (-42.0, -83.0),\n",
       "  (-44.0, -81.0),\n",
       "  (-47.0, -78.0),\n",
       "  (-48.0, -76.0),\n",
       "  (-50.0, -74.0),\n",
       "  (-51.0, -72.0),\n",
       "  (-54.0, -69.0),\n",
       "  (-56.0, -67.0),\n",
       "  (-59.0, -64.0),\n",
       "  (-61.0, -62.0),\n",
       "  (-62.0, -60.0),\n",
       "  (-64.0, -58.0),\n",
       "  (-65.0, -57.0),\n",
       "  (-68.0, -53.0),\n",
       "  (-69.0, -52.0),\n",
       "  (-70.0, -51.0),\n",
       "  (-71.0, -49.0),\n",
       "  (-73.0, -47.0),\n",
       "  (-74.0, -45.0),\n",
       "  (-76.0, -41.0),\n",
       "  (-77.0, -38.0),\n",
       "  (-79.0, -34.0),\n",
       "  (-80.0, -32.0),\n",
       "  (-81.0, -29.0),\n",
       "  (-82.0, -24.0),\n",
       "  (-83.0, -22.0),\n",
       "  (-84.0, -19.0),\n",
       "  (-84.0, -17.0),\n",
       "  (-85.0, -14.0),\n",
       "  (-85.0, -9.0),\n",
       "  (-86.0, -6.0),\n",
       "  (-86.0, -3.0),\n",
       "  (-86.0, 0.0),\n",
       "  (-85.0, 5.0),\n",
       "  (-85.0, 8.0),\n",
       "  (-85.0, 11.0),\n",
       "  (-84.0, 16.0),\n",
       "  (-82.0, 21.0),\n",
       "  (-82.0, 24.0),\n",
       "  (-81.0, 27.0),\n",
       "  (-80.0, 29.0),\n",
       "  (-77.0, 35.0),\n",
       "  (-76.0, 37.0),\n",
       "  (-73.0, 42.0),\n",
       "  (-72.0, 44.0),\n",
       "  (-70.0, 47.0),\n",
       "  (-66.0, 51.0),\n",
       "  (-64.0, 53.0),\n",
       "  (-62.0, 55.0),\n",
       "  (-56.0, 59.0),\n",
       "  (-51.0, 63.0),\n",
       "  (-48.0, 65.0),\n",
       "  (-45.0, 67.0),\n",
       "  (-42.0, 69.0),\n",
       "  (-37.0, 72.0),\n",
       "  (-34.0, 73.0),\n",
       "  (-32.0, 75.0),\n",
       "  (-29.0, 76.0),\n",
       "  (-27.0, 77.0),\n",
       "  (-25.0, 78.0),\n",
       "  (-22.0, 78.0),\n",
       "  (-20.0, 79.0),\n",
       "  (-17.0, 79.0),\n",
       "  (-15.0, 79.0),\n",
       "  (-13.0, 79.0),\n",
       "  (-11.0, 79.0),\n",
       "  (-6.0, 79.0),\n",
       "  (-4.0, 79.0),\n",
       "  (-2.0, 79.0),\n",
       "  (-1.0, 78.0),\n",
       "  (1.0, 78.0),\n",
       "  (3.0, 77.0),\n",
       "  (5.0, 76.0),\n",
       "  (7.0, 75.0),\n",
       "  (9.0, 73.0),\n",
       "  (11.0, 72.0),\n",
       "  (13.0, 71.0),\n",
       "  (15.0, 69.0),\n",
       "  (17.0, 67.0),\n",
       "  (19.0, 66.0),\n",
       "  (21.0, 64.0),\n",
       "  (23.0, 62.0),\n",
       "  (25.0, 60.0),\n",
       "  (29.0, 57.0),\n",
       "  (31.0, 55.0),\n",
       "  (32.0, 53.0),\n",
       "  (34.0, 51.0),\n",
       "  (36.0, 48.0),\n",
       "  (38.0, 46.0),\n",
       "  (40.0, 44.0),\n",
       "  (42.0, 41.0),\n",
       "  (43.0, 39.0),\n",
       "  (47.0, 34.0),\n",
       "  (49.0, 31.0),\n",
       "  (50.0, 29.0),\n",
       "  (52.0, 26.0),\n",
       "  (54.0, 19.0),\n",
       "  (55.0, 16.0),\n",
       "  (55.0, 13.0),\n",
       "  (55.0, 9.0),\n",
       "  (55.0, 5.0),\n",
       "  (55.0, 2.0),\n",
       "  (55.0, -4.0),\n",
       "  (55.0, -8.0),\n",
       "  (55.0, -10.0),\n",
       "  (56.0, -16.0),\n",
       "  (57.0, -18.0),\n",
       "  (58.0, -20.0),\n",
       "  (59.0, -22.0),\n",
       "  (60.0, -24.0),\n",
       "  (61.0, -26.0),\n",
       "  (62.0, -28.0),\n",
       "  (64.0, -32.0),\n",
       "  (65.0, -34.0),\n",
       "  (66.0, -36.0),\n",
       "  (67.0, -38.0),\n",
       "  (68.0, -39.0),\n",
       "  (69.0, -41.0),\n",
       "  (70.0, -43.0),\n",
       "  (70.0, -45.0),\n",
       "  (71.0, -46.0),\n",
       "  (72.0, -49.0),\n",
       "  (73.0, -52.0),\n",
       "  (73.0, -55.0),\n",
       "  (73.0, -57.0),\n",
       "  (72.0, -60.0),\n",
       "  (72.0, -62.0),\n",
       "  (72.0, -64.0),\n",
       "  (72.0, -65.0),\n",
       "  (72.0, -67.0),\n",
       "  (72.0, -70.0),\n",
       "  (72.0, -71.0),\n",
       "  (72.0, -73.0),\n",
       "  (72.0, -74.0),\n",
       "  (72.0, -76.0),\n",
       "  (72.0, -77.0),\n",
       "  (72.0, -78.0),\n",
       "  (71.0, -79.0),\n",
       "  (71.0, -80.0),\n",
       "  (70.0, -81.0),\n",
       "  (70.0, -82.0),\n",
       "  (70.0, -81.0),\n",
       "  (70.0, -80.0),\n",
       "  (70.0, -79.0),\n",
       "  (70.0, -78.0),\n",
       "  (70.0, -77.0),\n",
       "  (70.0, -76.0),\n",
       "  (70.0, -75.0),\n",
       "  (70.0, -74.0),\n",
       "  (70.0, -70.0),\n",
       "  (70.0, -68.0),\n",
       "  (70.0, -64.0),\n",
       "  (70.0, -62.0),\n",
       "  (70.0, -58.0),\n",
       "  (70.0, -56.0),\n",
       "  (70.0, -53.0),\n",
       "  (70.0, -52.0),\n",
       "  (70.0, -49.0),\n",
       "  (70.0, -44.0),\n",
       "  (71.0, -41.0),\n",
       "  (71.0, -35.0),\n",
       "  (71.0, -32.0),\n",
       "  (72.0, -29.0),\n",
       "  (72.0, -26.0),\n",
       "  (72.0, -23.0),\n",
       "  (73.0, -17.0),\n",
       "  (73.0, -14.0),\n",
       "  (74.0, -7.0),\n",
       "  (75.0, -1.0),\n",
       "  (75.0, 3.0),\n",
       "  (75.0, 6.0),\n",
       "  (76.0, 16.0),\n",
       "  (77.0, 22.0),\n",
       "  (77.0, 25.0),\n",
       "  (78.0, 28.0),\n",
       "  (79.0, 38.0),\n",
       "  (80.0, 42.0),\n",
       "  (81.0, 48.0),\n",
       "  (82.0, 55.0),\n",
       "  (83.0, 62.0),\n",
       "  (84.0, 65.0),\n",
       "  (85.0, 71.0),\n",
       "  (86.0, 77.0),\n",
       "  (86.0, 82.0),\n",
       "  (86.0, 86.0),\n",
       "  (86.0, 88.0),\n",
       "  (86.0, 92.0),\n",
       "  (85.0, 96.0),\n",
       "  (85.0, 97.0),\n",
       "  (84.0, 99.0),\n",
       "  (83.0, 102.0),\n",
       "  (82.0, 102.0),\n",
       "  (80.0, 101.0),\n",
       "  (79.0, 100.0)]]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_normalized['a'][50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump this to JSON as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"char74k-normalized.json\", \"w\") as fh:\n",
    "    json.dump(chars_normalized, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Works cited\n",
    "\n",
    "T. E. de Campos, B. R. Babu and M. Varma. [Character recognition in natural images](http://personal.ee.surrey.ac.uk/Personal/T.Decampos/papers/decampos_etal_visapp2009.pdf). In Proceedings of the International Conference on Computer Vision Theory and Applications (VISAPP), Lisbon, Portugal, February 2009. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
